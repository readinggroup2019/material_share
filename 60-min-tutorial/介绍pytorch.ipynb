{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"介绍pytorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO9qtYIkVw5W2T6J4zpF1bD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"cnA4glrFNjB2","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","import torch\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UI357GKzNo9Q","colab_type":"text"},"source":["# 1.Getting Started With Pytorch\n","\n","```\n","from __future__ import print_function\n","import torch\n","```\n","## 1.1 What is Pytorch?\n","[document](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)\n","\n","Pytorch is an open source machine learning framework that accelerates the path from research prototyping to production deployment.\n","\n","## 1.2 Basic knowledge\n","\n","### 1.2.1 Tensors\n","[Document](https://pytorch.org/docs/stable/tensors.html)\n","* Tensors are similar to NumPy’s ndarrays\n","* Tensors can be used on a GPU to accelerate computing.\n","\n","#### torch.Tensor\n","A ```torch.Tensor``` is a multi-dimensional matrix containing elements of a **single data type**.\n","\n","* Data type:\n"," * There are **9** different data types available:\n"," * ```torch.double```\n"," * ```torch.int```\n"," * ```torch.bool```\n"," * ...\n","* CPU/GPU\n"," * Tensor can be either CPU tensor or GPU tensor\n","\n","So there are $2*9=18$ different types of tensor.\n","\n","```torch.Tensor``` is an alias for the default tensor type (torch.FloatTensor)\n","\n","### 1.2.2 Creating a tensor in PyTorch\n","\n","* Declare an uninitialized matrix with unknown values.\n","```\n","x = torch.empty(5, 3)\n","```\n","* Construct a randomly initialized matrix(uniform(0,1) random variables):\n","```\n","x = torch.rand(5, 3)\n","```\n","* Construct a matrix filled zeros and of dtype long:\n","```\n","x = torch.zeros(5, 3, dtype=torch.long)\n","```\n","* Construct a tensor directly from data(from a Python ```1ist```):\n","```\n","x = torch.tensor([[1., -1.], [1., -1.]])\n","x = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\n","```\n","* Construct a tensor using numpy array: ```torch.tensor() ``` always copies(deep copy) ```data```. If you want to avoid a copy, use ```torch.as_tensor()```.:\n","```\n","x = torch.tensor([[1., -1.], [1., -1.]])\n","y = torch.tensor(x)\n","z = torch.as_tensor(x)\n","```\n","  These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user.\n"," * ```new_*``` methods. Create a tensor with similar type but different size as another tensor.\n"," ```\n","x = x.new_ones(5, 3, dtype=torch.double)\n"," ```\n"," * ```torch.*_like``` methods. Create a tensor with the same size (and similar types) as another tensor.\n"," ```\n","x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n"," ```\n","\n","### 1.2.3 Some Operations\n","[Document about operators](https://pytorch.org/docs/stable/torch.html)\n","* Get size: ```size()```\n","\n"]},{"cell_type":"code","metadata":{"id":"dltG_pEYS73A","colab_type":"code","outputId":"2e6fe932-934b-4bb0-8c32-21939963c765","executionInfo":{"status":"ok","timestamp":1590115985965,"user_tz":-480,"elapsed":1156,"user":{"displayName":"Micheal C","photoUrl":"","userId":"12796681543888505277"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x = torch.tensor([5.5, 3])\n","print(x.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([2])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y1l6MSNFTPEL","colab_type":"text"},"source":["* Addition\n"," * ```+```\n"," * ```torch.add()```\n"," * ```tensor.add_()```"]},{"cell_type":"code","metadata":{"id":"nQRu2o2FTY__","colab_type":"code","outputId":"cdd4fce8-9466-4595-bfb0-c4af026a4010","executionInfo":{"status":"ok","timestamp":1590117383396,"user_tz":-480,"elapsed":999,"user":{"displayName":"Micheal C","photoUrl":"","userId":"12796681543888505277"}},"colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["x = torch.tensor([[0,0],[10,10]])\n","y = torch.rand(2, 2)\n","\n","print(x + y)\n","\n","print(torch.add(x, y))\n","\n","# providing an output tensor as argument\n","result = torch.empty(5, 3)\n","torch.add(x, y, out=result)\n","print(result)\n","\n","# adds x to y\n","y.add_(x)\n","print(y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[ 0.1443,  0.4542],\n","        [10.0129, 10.4402]])\n","tensor([[ 0.1443,  0.4542],\n","        [10.0129, 10.4402]])\n","tensor([[ 0.1443,  0.4542],\n","        [10.0129, 10.4402]])\n","tensor([[ 0.1443,  0.4542],\n","        [10.0129, 10.4402]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0CvuEc_dTbYY","colab_type":"text"},"source":["> Note: Any operation that mutates a tensor in-place is post-fixed with an ```_```. For example: ```x.copy_(y)```, ```x.t_()```, will change x\n","\n","*  NumPy-like indexing can be used."]},{"cell_type":"code","metadata":{"id":"6u0wLwu3WBl_","colab_type":"code","outputId":"3d03badf-c05e-43af-9fce-b31f8483ffa1","executionInfo":{"status":"ok","timestamp":1590117390237,"user_tz":-480,"elapsed":1189,"user":{"displayName":"Micheal C","photoUrl":"","userId":"12796681543888505277"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(x[:, 1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([ 0, 10])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9KFLixxRYlQ3","colab_type":"text"},"source":["* resize/reshape tensor: ```torch.view``` or ```torch.reshape```"]},{"cell_type":"code","metadata":{"id":"FZshG4ojYskt","colab_type":"code","outputId":"3939d932-606a-4a56-efc2-8b1f3074ef11","executionInfo":{"status":"ok","timestamp":1590117527551,"user_tz":-480,"elapsed":627,"user":{"displayName":"Micheal C","photoUrl":"","userId":"12796681543888505277"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x = torch.randn(4, 4)\n","y = x.view(16)\n","z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n","w = x.reshape(2,-1)\n","print(x.size(), y.size(), z.size(), w.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) torch.Size([2, 8])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8AbOHcqOZvq-","colab_type":"text"},"source":["* Get the value of an one-element tensor: ```.item()```"]},{"cell_type":"code","metadata":{"id":"BrbePSN4Z7kv","colab_type":"code","outputId":"2eed3b34-d815-4e08-e851-2c1939fa767f","executionInfo":{"status":"ok","timestamp":1590118333106,"user_tz":-480,"elapsed":1224,"user":{"displayName":"Micheal C","photoUrl":"","userId":"12796681543888505277"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["x = torch.randn(1)\n","print(x)\n","print(x.item())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([-0.5503])\n","-0.5503179430961609\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bSN2-xZNaQ7v","colab_type":"text"},"source":["## 1.3 NumPy Bridge\n","\n","It is easy to converte a Torch Tensor to a NumPy array and vice versa.\n","\n","* Torch Tensor to NumPy Array: ```tensor.numpy()```\n"," * The ndarray and tensor share the same value.\n"," * All the Tensors on the CPU except a CharTensor support converting to NumPy and back.\n"]},{"cell_type":"code","metadata":{"id":"dyfVGUgXagst","colab_type":"code","outputId":"b859a653-b3c5-46fa-bfff-da0dbe6a682a","executionInfo":{"status":"ok","timestamp":1590118090225,"user_tz":-480,"elapsed":940,"user":{"displayName":"Micheal C","photoUrl":"","userId":"12796681543888505277"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["a = torch.ones(5)\n","print(a)\n","b = a.numpy()\n","print(b)\n","\n","# They change in value simultaneously.\n","a.add_(1)\n","print(a)\n","print(b)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([1., 1., 1., 1., 1.])\n","[1. 1. 1. 1. 1.]\n","tensor([2., 2., 2., 2., 2.])\n","[2. 2. 2. 2. 2.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e8SFxQxvbos1","colab_type":"text"},"source":["## 1.3 CUDA Tensors\n","\n","Tensors can be moved onto any device using the ```.to``` method.\n"]},{"cell_type":"code","metadata":{"id":"vZ94ENqnb2_p","colab_type":"code","outputId":"7e55f755-3296-4a27-dc40-80fd47ab170c","executionInfo":{"status":"ok","timestamp":1590118516392,"user_tz":-480,"elapsed":1232,"user":{"displayName":"Micheal C","photoUrl":"","userId":"12796681543888505277"}},"colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["x = torch.randn(1)\n","# We will use ``torch.device`` objects to move tensors in and out of GPU\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")          # a CUDA device object\n","    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n","    print(\"y on GPU:\\n \",y)\n","    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n","    print(\"x moved to GPU:\\n \",x)\n","    z = x + y\n","    print(\"z= x+ y on GPU:\\n\",z)\n","    print(\"move z to CPU:\\n\",z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"],"execution_count":0,"outputs":[{"output_type":"stream","text":["y on GPU:\n","  tensor([1.], device='cuda:0')\n","x moved to GPU:\n","  tensor([-0.3136], device='cuda:0')\n","z= x+ y on GPU:\n"," tensor([0.6864], device='cuda:0')\n","move z to CPU:\n"," tensor([0.6864], dtype=torch.float64)\n"],"name":"stdout"}]}]}